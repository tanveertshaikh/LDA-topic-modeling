{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling using Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vox News corpus is a collection of all Vox articles published before March 21, 2017. Vox Media released this dataset as part of the KDD 2017 Workshop on Data Science + Journalism. Their goal for publishing this dataset was to enable data science researchers to apply various techniques on a news dataset.\n",
    "\n",
    "<b>The dataset consists of 22,994 news articles with their titles, author names, categories, published dates, updated on dates, links to the articles and their short descriptions (8 columns). While visualizing the dataset, I noticed that all the articles are clustered by 185 distinct categories. Out of those articles, 7145 articles were tageed by the category \"The Latest\". It cannot be a coincidence that such a large number of articles would be tagged by a generic category. Hence, I decided to address this problem by unsupervised learning because the categories of articles cannot be predicted beforehand neither the articles can be tagged by their categories in the training dataset.</b>\n",
    "\n",
    "<b>We get a crude idea of the article by just skimming through the category of the article. Hence, topic modeling is useful for categorizing or ranking articles which are remaining to be read by an individual. Moreover, clustering of articles based on topics also enable them to be organized by groups of similar topics inside a database. This simplifies the collective analysis of such Big Data especially in the field of News and Journalism where an enormous amount of data is archived and retrieved only when needed. Categorical clustering will also make information retrieval quicker and more efficient.</b>\n",
    "\n",
    "We can analyze the title, short description and the body of these 7145 articles and predict their categories by using Topic Modeling.\n",
    "\n",
    "In reality, analyzing the body would drastically improve the topic model. However, due to time constraints and proclivity towards minimalism, I have decided to drop the body column entirely. Also, parsing html tags in the body of articles would be a time-consuming task in itself.\n",
    "\n",
    "In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"cat\" and \"meow\" will appear in documents about cats, and \"the\" and \"is\" will appear equally in both. A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. The \"topics\" produced by topic modeling techniques are clusters of similar words. A topic model captures this intuition in a mathematical framework, which allows examining a set of documents and discovering, based on the statistics of the words in each, what the topics might be and what each document's balance of topics is.\n",
    "\n",
    "Topic models are also referred to as probabilistic topic models, which refers to statistical algorithms for discovering the latent semantic structures of an extensive text body. In the age of information, the amount of the written material we encounter each day is simply beyond our processing capacity. Topic models can help to organize and offer insights for us to understand large collections of unstructured text bodies. Originally developed as a text-mining tool, topic models have been used to detect instructive structures in data such as genetic information, images, and networks. They also have applications in other fields such as bioinformatics. [Source: https://en.wikipedia.org/wiki/Topic_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary python libraries and packages like numpy, pandas, matplotlib and scikit-learn have been imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import Tree, pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "# styling\n",
    "pd.set_option('display.max_columns',150)\n",
    "plt.style.use('bmh')\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bubble chart quantifies the number of articles written by different authors.  [Source: https://data.world/elenadata/vox-articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1](../bin/resources/articles-per-author.png \"Figure 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph signifies the gradual increase in the number of articles being published during each month. However, the average articles published in the months of 2017 and 2016 seems to be the similar.  [Source: https://data.world/elenadata/vox-articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 2](../bin/resources/articles-by-month.png \"Figure 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire dataset consists of a total of 185 distinct topics. This bubble plot shows records grouped by category. We can observe that the category \"The Latest\" has the maximum number of records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 3](../bin/resources/records-by-category.png \"Figure 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar graph tells us the distribution of records around topics and also around different authors who have written about the same topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 4](../bin/resources/records-by-category-&-author.png \"Figure 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of algorithms developed for topic modeling which use singular value decomposition (SVD) and the method of moments. These algorithms are listed below:\n",
    "<ul>Explicit semantic analysis</ul>\n",
    "<ul>Latent semantic analysis</ul>\n",
    "<ul>Latent Dirichlet Allocation (LDA)</ul>\n",
    "<ul>Hierarchical Dirichlet process</ul>\n",
    "<ul>Non-Negative Matrix Factorization (NMF)</ul>\n",
    "\n",
    "I decided to use LDA as it is widely praised by researchers and data scientists. Owing to my Data Mining project, I also had prior experience on working with Gensim library in Python which has a robust LDA model. LDA is a kind of probabilistic model that exploits similarity between data and extracts inference from the resulting analysis.\n",
    "\n",
    "In natural language processing, Latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. For example, if observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's creation is attributable to one of the document's topics. LDA is an example of a topic model and was first presented as a graphical model for topic discovery by David Blei, Andrew Ng, and Michael I. Jordan in 2003. Essentially the same model was also proposed independently by J. K. Pritchard, M. Stephens, and P. Donnelly in the study of population genetics in 2000. Both papers have been highly influential, with 19858 and 20416 citations respectively by August 2017.  [Source: https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will auto-download the required NLTK modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tanveershaikh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tanveershaikh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLTK, I am creating a corpus of English words and also an object of the lemmatizer is being created using WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization and Global Variables\n",
    "\n",
    "dictionary = dict.fromkeys(words.words(), None)\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset (dsjVoxArticles.tsv) - Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is being fetched from the data.world URL and converted into a Pandas DataFrame in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = \"https://query.data.world/s/ee6arp6cngynnoj4hvyuhckn3tb4hj\"\n",
    "df = pd.read_csv(url, delimiter = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting only the articles having category as 'The Latest' and dropping all other articles which have their coorect categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7152, 8)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[df['category'] == 'The Latest']\n",
    "print(df.shape)\n",
    "print(df.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section deals with exploring and analyzing the dataset. It will give us a deeper understanding of the dataset by making us familiar with all the rows and columns of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>published_date</th>\n",
       "      <th>updated_on</th>\n",
       "      <th>slug</th>\n",
       "      <th>blurb</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Obama wants to fight gerrymandering once he le...</td>\n",
       "      <td>Andrew Prokop</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2014-04-15 18:00:02</td>\n",
       "      <td>2016-10-25 21:52:52</td>\n",
       "      <td>http://www.vox.com/2014/4/15/5604284/us-electi...</td>\n",
       "      <td>Our neighbor to the north solved its gerrymand...</td>\n",
       "      <td>&lt;p&gt;If Donald Trump wants to complain about US ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4/20: National Weed Day, explained</td>\n",
       "      <td>German Lopez</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2014-04-19 20:20:02</td>\n",
       "      <td>2016-04-21 00:09:02</td>\n",
       "      <td>http://www.vox.com/2014/4/19/5624560/why-is-42...</td>\n",
       "      <td>Tens of thousands are celebrating a less tradi...</td>\n",
       "      <td>&lt;p&gt;It is 4/20, the day tens of thousands of Am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>You're Shakespeare, but you're playing Hamlet ...</td>\n",
       "      <td>Dara Lind</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2014-04-20 15:30:02</td>\n",
       "      <td>2016-06-14 20:57:15</td>\n",
       "      <td>http://www.vox.com/2014/4/20/5628860/hes-unive...</td>\n",
       "      <td>Gregory Rabassa, who died Tuesday, is probably...</td>\n",
       "      <td>&lt;p&gt;&lt;i&gt;Gregory Rabassa, who died Tuesday, was a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>This awesome footage of DC was shot by an ille...</td>\n",
       "      <td>Zack Beauchamp</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2014-05-05 13:00:03</td>\n",
       "      <td>2015-05-15 15:45:54</td>\n",
       "      <td>http://www.vox.com/2014/5/5/5676010/dc-drone-f...</td>\n",
       "      <td>And the troubling things it tells us about the...</td>\n",
       "      <td>&lt;p&gt;As one of those rare people who actually gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>A viewer's guide to the 2016 National Spelling...</td>\n",
       "      <td>Alex Abad-Santos</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2014-05-27 18:20:10</td>\n",
       "      <td>2016-05-25 15:10:48</td>\n",
       "      <td>http://www.vox.com/2014/5/27/5754264/a-viewers...</td>\n",
       "      <td>What you need to know before the carnage begins.</td>\n",
       "      <td>&lt;p&gt;This week, one of the most brutal competiti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title            author  \\\n",
       "31   Obama wants to fight gerrymandering once he le...     Andrew Prokop   \n",
       "56                  4/20: National Weed Day, explained      German Lopez   \n",
       "64   You're Shakespeare, but you're playing Hamlet ...         Dara Lind   \n",
       "116  This awesome footage of DC was shot by an ille...    Zack Beauchamp   \n",
       "231  A viewer's guide to the 2016 National Spelling...  Alex Abad-Santos   \n",
       "\n",
       "       category       published_date           updated_on  \\\n",
       "31   The Latest  2014-04-15 18:00:02  2016-10-25 21:52:52   \n",
       "56   The Latest  2014-04-19 20:20:02  2016-04-21 00:09:02   \n",
       "64   The Latest  2014-04-20 15:30:02  2016-06-14 20:57:15   \n",
       "116  The Latest  2014-05-05 13:00:03  2015-05-15 15:45:54   \n",
       "231  The Latest  2014-05-27 18:20:10  2016-05-25 15:10:48   \n",
       "\n",
       "                                                  slug  \\\n",
       "31   http://www.vox.com/2014/4/15/5604284/us-electi...   \n",
       "56   http://www.vox.com/2014/4/19/5624560/why-is-42...   \n",
       "64   http://www.vox.com/2014/4/20/5628860/hes-unive...   \n",
       "116  http://www.vox.com/2014/5/5/5676010/dc-drone-f...   \n",
       "231  http://www.vox.com/2014/5/27/5754264/a-viewers...   \n",
       "\n",
       "                                                 blurb  \\\n",
       "31   Our neighbor to the north solved its gerrymand...   \n",
       "56   Tens of thousands are celebrating a less tradi...   \n",
       "64   Gregory Rabassa, who died Tuesday, is probably...   \n",
       "116  And the troubling things it tells us about the...   \n",
       "231   What you need to know before the carnage begins.   \n",
       "\n",
       "                                                  body  \n",
       "31   <p>If Donald Trump wants to complain about US ...  \n",
       "56   <p>It is 4/20, the day tens of thousands of Am...  \n",
       "64   <p><i>Gregory Rabassa, who died Tuesday, was a...  \n",
       "116  <p>As one of those rare people who actually gr...  \n",
       "231  <p>This week, one of the most brutal competiti...  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints out the first 5 rows of data in the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>published_date</th>\n",
       "      <th>updated_on</th>\n",
       "      <th>slug</th>\n",
       "      <th>blurb</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23017</th>\n",
       "      <td>Bad typography has ruined more than just the O...</td>\n",
       "      <td>Christophe Haubursin</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2017-03-21 19:10:01</td>\n",
       "      <td>2017-03-21 19:34:47</td>\n",
       "      <td>http://www.vox.com/2017/3/21/15004126/oscars-g...</td>\n",
       "      <td></td>\n",
       "      <td>&lt;p id=\"BkGLCG\"&gt;You can blame a lot of people f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23018</th>\n",
       "      <td>Neil Gorsuch is denying former students' claim...</td>\n",
       "      <td>Emily Crockett</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2017-03-21 18:50:02</td>\n",
       "      <td>2017-03-21 19:51:37</td>\n",
       "      <td>http://www.vox.com/identities/2017/3/21/150091...</td>\n",
       "      <td></td>\n",
       "      <td>&lt;p id=\"fSQrxr\"&gt;During his confirmation hearing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23019</th>\n",
       "      <td>Marijuana legalization opponents warned teen p...</td>\n",
       "      <td>German Lopez</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2017-03-21 19:30:01</td>\n",
       "      <td>2017-03-21 19:51:00</td>\n",
       "      <td>http://www.vox.com/policy-and-politics/2017/3/...</td>\n",
       "      <td></td>\n",
       "      <td>&lt;p id=\"6OljE3\"&gt;So far, &lt;a href=\"http://www.vox...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23020</th>\n",
       "      <td>4 ways the House health care vote could go dow...</td>\n",
       "      <td>Andrew Prokop</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2017-03-21 21:41:12</td>\n",
       "      <td>2017-03-21 23:46:25</td>\n",
       "      <td>http://www.vox.com/policy-and-politics/2017/3/...</td>\n",
       "      <td>This Thursday should be an eventful day.</td>\n",
       "      <td>&lt;p id=\"5WuiOu\"&gt;House Speaker Paul Ryan still a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23022</th>\n",
       "      <td>Oscars 2017: every movie nominated for an Acad...</td>\n",
       "      <td>Sarah Frostenson</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2017-02-23 20:20:01</td>\n",
       "      <td>2017-02-26 14:10:56</td>\n",
       "      <td>http://www.vox.com/a/oscars-2017-movies-nominees</td>\n",
       "      <td>Yes, even 13 Hours: The Secret Soldiers of Ben...</td>\n",
       "      <td>&lt;h2 id=\"RCAyzl\"&gt;&lt;a href=\"http://www.imdb.com/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "23017  Bad typography has ruined more than just the O...   \n",
       "23018  Neil Gorsuch is denying former students' claim...   \n",
       "23019  Marijuana legalization opponents warned teen p...   \n",
       "23020  4 ways the House health care vote could go dow...   \n",
       "23022  Oscars 2017: every movie nominated for an Acad...   \n",
       "\n",
       "                     author    category       published_date  \\\n",
       "23017  Christophe Haubursin  The Latest  2017-03-21 19:10:01   \n",
       "23018        Emily Crockett  The Latest  2017-03-21 18:50:02   \n",
       "23019          German Lopez  The Latest  2017-03-21 19:30:01   \n",
       "23020         Andrew Prokop  The Latest  2017-03-21 21:41:12   \n",
       "23022      Sarah Frostenson  The Latest  2017-02-23 20:20:01   \n",
       "\n",
       "                updated_on                                               slug  \\\n",
       "23017  2017-03-21 19:34:47  http://www.vox.com/2017/3/21/15004126/oscars-g...   \n",
       "23018  2017-03-21 19:51:37  http://www.vox.com/identities/2017/3/21/150091...   \n",
       "23019  2017-03-21 19:51:00  http://www.vox.com/policy-and-politics/2017/3/...   \n",
       "23020  2017-03-21 23:46:25  http://www.vox.com/policy-and-politics/2017/3/...   \n",
       "23022  2017-02-26 14:10:56   http://www.vox.com/a/oscars-2017-movies-nominees   \n",
       "\n",
       "                                                   blurb  \\\n",
       "23017                                                      \n",
       "23018                                                      \n",
       "23019                                                      \n",
       "23020           This Thursday should be an eventful day.   \n",
       "23022  Yes, even 13 Hours: The Secret Soldiers of Ben...   \n",
       "\n",
       "                                                    body  \n",
       "23017  <p id=\"BkGLCG\">You can blame a lot of people f...  \n",
       "23018  <p id=\"fSQrxr\">During his confirmation hearing...  \n",
       "23019  <p id=\"6OljE3\">So far, <a href=\"http://www.vox...  \n",
       "23020  <p id=\"5WuiOu\">House Speaker Paul Ryan still a...  \n",
       "23022   <h2 id=\"RCAyzl\"><a href=\"http://www.imdb.com/...  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints out the last 5 rows of data in the dataset\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>published_date</th>\n",
       "      <th>updated_on</th>\n",
       "      <th>slug</th>\n",
       "      <th>blurb</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7152</td>\n",
       "      <td>7152</td>\n",
       "      <td>7152</td>\n",
       "      <td>7152</td>\n",
       "      <td>7152</td>\n",
       "      <td>7152</td>\n",
       "      <td>7152</td>\n",
       "      <td>7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7133</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>7111</td>\n",
       "      <td>7071</td>\n",
       "      <td>7152</td>\n",
       "      <td>5510</td>\n",
       "      <td>7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Republican debate 2016 live stream: time, TV s...</td>\n",
       "      <td>German Lopez</td>\n",
       "      <td>The Latest</td>\n",
       "      <td>2016-05-19 12:00:03</td>\n",
       "      <td>2016-11-16 21:01:35</td>\n",
       "      <td>http://www.vox.com/science-and-health/2017/1/1...</td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;&lt;a href=\"http://www.vox.com/cards/gender-wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>648</td>\n",
       "      <td>7152</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title        author  \\\n",
       "count                                                7152          7152   \n",
       "unique                                               7133           220   \n",
       "top     Republican debate 2016 live stream: time, TV s...  German Lopez   \n",
       "freq                                                    5           648   \n",
       "\n",
       "          category       published_date           updated_on  \\\n",
       "count         7152                 7152                 7152   \n",
       "unique           1                 7111                 7071   \n",
       "top     The Latest  2016-05-19 12:00:03  2016-11-16 21:01:35   \n",
       "freq          7152                    3                   12   \n",
       "\n",
       "                                                     slug blurb  \\\n",
       "count                                                7152  7152   \n",
       "unique                                               7152  5510   \n",
       "top     http://www.vox.com/science-and-health/2017/1/1...         \n",
       "freq                                                    1  1598   \n",
       "\n",
       "                                                     body  \n",
       "count                                                7152  \n",
       "unique                                               7152  \n",
       "top     <p><a href=\"http://www.vox.com/cards/gender-wa...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics about the data column-wise\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, the data pre-processing steps include dropping the irrelevant columns from the dataframe and then dropping the rows having any of the values as NaN.\n",
    "\n",
    "But before doing that step, empty cell locations are being checked or the ones having whitespaces. These rows are marked and dropped entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning the dataset...\")\n",
    "columns = ['author','category','published_date','updated_on','slug','body']\n",
    "df.drop(columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7152, 2)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to drop missing values as we have a large number of records to train on and the number of records having at least 1 value missing is negligible. Hence, it will only have minuscule effect on our model’s performance which can be neglected. <br>\n",
    "\n",
    "<br>I am deleting the author, published_date and updated_on columns as they are irrelevant to my end goal, which is, topic modeling using the title and blurb (short description).<br>\n",
    "\n",
    "<br>I have also decided to delete the slug and body columns as this is just a naive implementation of topic modeling. I will have to consider those two columns after completing this project to make my topic modeling more coherent.\n",
    "Also, I am dropping the category column as I am trying to determine that attribute itself and unsupervised learning does not require the training labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing missing values...\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing missing values...\")\n",
    "df['blurb'].replace(' ', np.nan, inplace = True)\n",
    "df.dropna(axis = 0, how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am performing the operation of cleaning up weird characters from the dataframe. These characters exist because the string data was decoded in another format and is now being encoded in UTF-8 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking values...\n"
     ]
    }
   ],
   "source": [
    "df.apply(lambda x: x.apply(lambda y: y.strip() if type(y) == type('') else y), axis=0)\n",
    "\n",
    "df['blurb'] = df['blurb'].str.replace('â€™',\"'\").str.replace('â€”',\"-\").str.replace('â€œ','\"').str.replace('â€','\"')\n",
    "df['blurb'] = df['blurb'].str.strip()\n",
    "df['blurb'] = df['blurb'].apply(lambda x: x.strip())\n",
    "\n",
    "df['title'] = df['title'].str.replace('â€™',\"'\").str.replace('â€”',\"-\").str.replace('â€œ','\"').str.replace('â€','\"')\n",
    "df['title'] = df['title'].str.strip()\n",
    "df['title'] = df['title'].apply(lambda x: x.strip())\n",
    "\n",
    "# Checking Values\n",
    "print(\"Checking values...\")\n",
    "# print(df.at[23003, 'blurb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am keeping only the distinct (unique) values of titles as well as of the blurb and dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('blurb')\n",
    "df = df.drop_duplicates('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting our dataset into a collection of 5495 documents with just 1 column consisting of title concatenated with blurb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['documents'] = df['title'].map(str) + '. ' + df['blurb'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['title','blurb']\n",
    "df.drop(columns, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
